{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddsuresh97/prep_tutorial/blob/main/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "0yPo3BgzQEit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download files - run this only once\n",
        "\n",
        "import zipfile\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/siddsuresh97/prep_tutorial/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/tmp/prep_cnn_psychophysics.zip\"\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/tmp/prep_cnn_psychophysics.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_eY8yM9wIKa6",
        "outputId": "4115ee03-4df2-4176-f41f-42491f9f6e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-06 15:33:03--  https://github.com/siddsuresh97/prep_tutorial/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/siddsuresh97/prep_tutorial/zip/refs/heads/main [following]\n",
            "--2022-07-06 15:33:03--  https://codeload.github.com/siddsuresh97/prep_tutorial/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/tmp/prep_cnn_psychophysics.zip’\n",
            "\n",
            "/tmp/prep_cnn_psych     [       <=>          ] 100.93M  19.5MB/s    in 5.3s    \n",
            "\n",
            "2022-07-06 15:33:08 (19.1 MB/s) - ‘/tmp/prep_cnn_psychophysics.zip’ saved [105834558]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If restart runtime"
      ],
      "metadata": {
        "id": "SCWmYvfTQHYE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qNnGKH1LXwYi",
        "cellView": "form",
        "outputId": "fe415e2e-0444-4374-9bff-ad61447e7210",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 793 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 381 kB 53.6 MB/s \n",
            "\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.30 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ],
      "source": [
        "#@title imports\n",
        "\n",
        "!pip install deepdish -q\n",
        "!pip install ipdb -q\n",
        "\n",
        "import logging\n",
        "import random\n",
        "import ast\n",
        "import zipfile\n",
        "import gc\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import deepdish as dd\n",
        "\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_resnet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "import os\n",
        "from turtle import title\n",
        "import ipdb\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.graphics.factorplots import interaction_plot\n",
        "from statsmodels.formula.api import ols\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFOIVV0XIEqZ"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = '/tmp/prep_tutorial-main'\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, \"results/\")\n",
        "BATCH_SIZE = 512\n",
        "INTERMEDIATE_LAYER_NAMES = ['avg_pool', 'pool1_pool']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sJfxRVikIEqZ"
      },
      "outputs": [],
      "source": [
        "#@title helper functions - intermediate layer features\n",
        "\n",
        "\n",
        "def store_dataset_fnames(intermediate_layer_names, dataset_dir, batch_size, stim_type, features_dir):\n",
        "    # Stores filenames of stimuli in a pickle file\n",
        "    # Fnames of stimuli contain metadata about labels\n",
        "    # Only one intermediate layer is used because the fnames are same regardless of the intermediate layer\n",
        "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input_resnet50)\n",
        "    if not os.path.exists(features_dir):\n",
        "        os.makedirs(features_dir)\n",
        "    for layer in intermediate_layer_names[0]:\n",
        "        generator = datagen.flow_from_directory(dataset_dir, shuffle = False, batch_size = batch_size)\n",
        "        filenames = generator.filenames\n",
        "        fname_dict = {'fnames':filenames}\n",
        "        pickle.dump( fname_dict, open(os.path.join(features_dir,\"filenames_{}.p\".format(stim_type)), \"wb\" ))  \n",
        "    logging.info(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n",
        "\n",
        "def store_intermediate_layer_features(model_name, intermediate_layer_names, dataset_dir, batch_size, stim_type, features_dir):\n",
        "    for layer in intermediate_layer_names:\n",
        "        logging.info('------------------------------- {} ----------------------------'.format(layer))\n",
        "        if model_name == 'resnet50':\n",
        "            datagen = ImageDataGenerator(preprocessing_function=preprocess_input_resnet50)\n",
        "        else:\n",
        "            logging.error('Models apart from resnet50 not implemented')\n",
        "        generator = datagen.flow_from_directory(dataset_dir, shuffle = False, batch_size = batch_size, target_size = (224, 224))\n",
        "        len = generator.n\n",
        "        batches = np.ceil(len/batch_size)\n",
        "        extract_and_store(model_name, 1, layer, generator, features_dir, stim_type, batches)\n",
        "        extract_and_store(model_name, 2, layer, generator, features_dir, stim_type, batches)\n",
        "    return\n",
        "\n",
        "\n",
        "def extract_intermediate_layer_representations(model_name, intermediate_layer_names, dataset_base_dir, batch_size, stim_type, features_base_dir, conditions, exp_name):\n",
        "    \"\"\"\n",
        "    This function extracts and stores intermediate layer representations given a model\n",
        "    and a dataset   \n",
        "    \"\"\"\n",
        "    if exp_name == '1a':\n",
        "        stim_name = 'random_stim'\n",
        "    elif exp_name == '1b':\n",
        "        stim_name = 'test_stim' \n",
        "    else:\n",
        "        logging.error('Only Exp 1a, 1b implemented')\n",
        "\n",
        "    # condition is set size if exp is 1a or 1b, otherwise it is color diveristy\n",
        "    for condition in conditions:\n",
        "        if exp_name in ['1a', '1b']:\n",
        "            dataset_dir = os.path.join(dataset_base_dir, '{}_generated_stimuli'.format(condition), stim_name)\n",
        "            features_dir = os.path.join(features_base_dir, 'set_size_{}'.format(condition))\n",
        "        elif exp_name in ['2a']:\n",
        "            stim_type = condition\n",
        "            dataset_dir = os.path.join(dataset_base_dir, condition)\n",
        "            features_dir = os.path.join(features_base_dir)\n",
        "        else:\n",
        "            logging.error('Only 1a, 1b, 2a activation extraction implemented')\n",
        "        store_dataset_fnames(intermediate_layer_names, dataset_dir, batch_size, stim_type, features_dir)\n",
        "        start = time.time()\n",
        "        store_intermediate_layer_features(model_name, intermediate_layer_names, dataset_dir, batch_size, stim_type, features_dir)\n",
        "        logging.info('Total time to extract intermediate layer reprsentations (in seconds): {}'.format(time.time()-start))\n",
        "\n",
        "\n",
        "def extract_and_store(model_name, part, layer, generator, features_dir, stim_type, batches):\n",
        "    '''\n",
        "    Extracts intermediate layer features and stores them in two h5 files\n",
        "    '''\n",
        "    if model_name == 'resnet50':\n",
        "        model = ResNet50(weights='imagenet', include_top=True)\n",
        "    else:\n",
        "        logging.error('Models apart from resnet not implementde')\n",
        "    extractor = tf.keras.Model(inputs=model.inputs,\n",
        "                                outputs=[model.get_layer(layer).output])\n",
        "    features_dict = {'fnames':[],'features':[]}\n",
        "    if part == 1:\n",
        "        min_range = 0\n",
        "        max_range = int(batches)//2\n",
        "    elif part == 2:\n",
        "        min_range = int(batches)//2\n",
        "        max_range = int(batches)\n",
        "    for batch in range(min_range, max_range):\n",
        "        time_for_generator_operation = time.time()\n",
        "        x,y = generator.next()\n",
        "        # logging.info('Time for generator %f' % time.time()-time_for_generator_operation)\n",
        "        time_for_prediction = time.time()\n",
        "        generator_features = extractor.predict(x)\n",
        "        features_dict['features'].append(generator_features)\n",
        "        # logging.info('Prediction Time = %f'%time.time()-time_for_prediction)\n",
        "        time_for_deletion = time.time()\n",
        "        del generator_features\n",
        "        # logging.info('Time_for_deletion = ', time.time()-time_for_deletion)\n",
        "        idx = (generator.batch_index - 1) * generator.batch_size\n",
        "        features_dict['fnames'].append(generator.filenames[idx : idx + generator.batch_size])\n",
        "    del extractor\n",
        "    del model\n",
        "    if not os.path.exists(features_dir):\n",
        "        os.makedirs(features_dir)\n",
        "    dd.io.save(os.path.join(features_dir, 'resnet_50_features_{}_{}_part_{}.h5'.format(stim_type, layer, part)), features_dict)\n",
        "    del features_dict\n",
        "    gc.collect()\n",
        "    clear_session()\n",
        "    logging.info(\"Saved {} part {}\".format(layer, part))\n",
        "    return \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title helper functions - Run experiment\n",
        "\n",
        "def run_exp(exp_name, features_dir, subsampling_levels, conditions, \n",
        "            intermediate_layer_names, results_dir, result_fname, performance_measure):\n",
        "    logging.info(\"Running experiement %s\" % exp_name)\n",
        "    if exp_name == '1c':\n",
        "        stim_type = 'test_stim'\n",
        "        analysis_fn = logistic_regression\n",
        "        analysis_type = 'logistic_regression'\n",
        "    elif exp_name in ['1a', '1b']:\n",
        "        if exp_name == '1a':\n",
        "            stim_type = 'ind'\n",
        "        elif exp_name == '1b':\n",
        "            stim_type = 'test_stim'\n",
        "        analysis_fn = linear_regression\n",
        "        analysis_type = 'linear_regression'\n",
        "    else:\n",
        "        logging.debug(\"NOT IMPLEMENTED FOR OTHER EXPERIMENTS\")\n",
        "    if \"1\" in exp_name:\n",
        "        set_sizes = conditions\n",
        "        for set_size in set_sizes:\n",
        "            logging.info('########  SET SIZE %d #########'%set_size)\n",
        "            intermediate_layer_feats_dir = os.path.join(features_dir, 'set_size_{}/'.format(set_size))\n",
        "            start_time = time.time()\n",
        "            number_of_random_features = subsampling_levels\n",
        "            results_test = {}\n",
        "            # results_number_of_samples = {}\n",
        "            for layer in intermediate_layer_names:\n",
        "                logging.info('####################       %s          ##########################'%layer)\n",
        "                network_results_test = {}\n",
        "                # network_results_number_of_samples = {}\n",
        "                # test_stim contains circles of multiple set sizes and ind stim only contains a single circle\n",
        "                data, labels = get_data_and_labels(stim_type = stim_type,\n",
        "                                                layer = layer,\n",
        "                                                intermediate_layer_feats_dir = intermediate_layer_feats_dir,\n",
        "                                                analysis_type = analysis_type, \n",
        "                                                condition = set_size)\n",
        "                for random_features_number in number_of_random_features:\n",
        "                    network_results_test[random_features_number] = {}\n",
        "                    # network_results_number_of_samples[random_features_number] = {}\n",
        "                    if data.shape[1]<random_features_number:\n",
        "                        network_results_test.update({random_features_number:float('nan')})\n",
        "                        continue\n",
        "                    # TO DO :- only sparse distribution now, maybe implement dim reduction too\n",
        "                    subsample_data = subsample_img_features(data, random_features_number, 100)\n",
        "                    if analysis_type == 'logistic_regression':\n",
        "                        for circle_size in range(labels.shape[1]):\n",
        "                            evalutaion_measure = analysis_fn(subsample_data, labels[:,circle_size], performance_measure, exp_name)\n",
        "                            network_results_test[random_features_number].update({circle_size:evalutaion_measure})\n",
        "                            # network_results_number_of_samples[random_features_number].update({circle_size:samples})\n",
        "                    elif analysis_type == 'linear_regression':\n",
        "                        evalutaion_measure = analysis_fn(subsample_data, labels, performance_measure, exp_name)\n",
        "                        network_results_test[random_features_number] = evalutaion_measure\n",
        "                    else:\n",
        "                        logging.error('Analysis type not implemented')\n",
        "                results_test.update({layer:network_results_test})\n",
        "                # results_number_of_samples.update({layer:network_results_number_of_samples})\n",
        "            dir_path = os.path.join(results_dir, exp_name, 'set_size_{}'.format(set_size))\n",
        "            if not os.path.exists(dir_path):\n",
        "                os.makedirs(dir_path)\n",
        "            with open(os.path.join(results_dir,exp_name, 'set_size_{}'.format(set_size), result_fname), 'wb') as f:\n",
        "                pickle.dump(results_test,f)\n",
        "            # with open(os.path.join(results_dir,exp_name, 'set_size_{}'.format(set_size), result_fname), 'wb') as f:\n",
        "            #   pickle.dump(results_number_of_samples,f)\n",
        "            logging.info('Total time %d'%(time.time()-start_time))\n",
        "    elif \"2\" in exp_name:\n",
        "        if exp_name == \"2a\":\n",
        "            analysis_type = 'logistic_regression'\n",
        "            analysis_fn = logistic_regression\n",
        "        elif exp_name == \"2b\":\n",
        "            analysis_type = 'logistic_regression'\n",
        "            analysis_fn = logistic_regression \n",
        "        elif exp_name == \"2c\":\n",
        "            analysis_type = 'logistic_regression'\n",
        "            analysis_fn = logistic_regression \n",
        "        else:\n",
        "            logging.error('Other experiments not implemented')\n",
        "        results_test = {}\n",
        "        number_of_random_features = subsampling_levels\n",
        "        start_time = time.time()\n",
        "        for layer in intermediate_layer_names:\n",
        "            network_results_test = {}\n",
        "            logging.info('####################       {}          ##########################'.format(layer))\n",
        "            if exp_name == \"2a\":\n",
        "                low_div_data, low_div_labels = get_data_and_labels(stim_type = 'low_diversity', layer = layer, \n",
        "                                                                intermediate_layer_feats_dir = features_dir, \n",
        "                                                                analysis_type='logistic_regression', \n",
        "                                                                condition='low_diversity')\n",
        "                high_div_data, high_div_labels = get_data_and_labels(stim_type = 'high_diversity', layer = layer, \n",
        "                                                                intermediate_layer_feats_dir = features_dir, \n",
        "                                                                analysis_type='logistic_regression', \n",
        "                                                                condition='high_diversity')\n",
        "            elif exp_name == \"2b\":\n",
        "                low_div_data, low_div_labels = get_data_and_labels(stim_type = 'low_diversity', layer = layer, \n",
        "                                                                intermediate_layer_feats_dir = features_dir, \n",
        "                                                                analysis_type='logistic_regression', \n",
        "                                                                condition='ind_color')\n",
        "                high_div_data, high_div_labels = get_data_and_labels(stim_type = 'high_diversity', layer = layer, \n",
        "                                                                intermediate_layer_feats_dir = features_dir, \n",
        "                                                                analysis_type='logistic_regression', \n",
        "                                                                condition='ind_color')\n",
        "            elif exp_name == \"2c\":\n",
        "                low_div_data, low_div_labels = get_data_and_labels(stim_type = 'low_diversity', layer = layer, \n",
        "                                                                intermediate_layer_feats_dir = features_dir, \n",
        "                                                                analysis_type='logistic_regression', \n",
        "                                                                condition='ind_letter')\n",
        "                high_div_data, high_div_labels = get_data_and_labels(stim_type = 'high_diversity', layer = layer, \n",
        "                                                                intermediate_layer_feats_dir = features_dir, \n",
        "                                                                analysis_type='logistic_regression', \n",
        "                                                                condition='ind_letter')\n",
        "            else:\n",
        "                logging.error('only implemented 2abc in exp 2')                    \n",
        "            data = np.concatenate((low_div_data, high_div_data))\n",
        "            labels = np.concatenate((low_div_labels, high_div_labels))\n",
        "            for random_features_number in number_of_random_features:\n",
        "                network_results_test[random_features_number] = {}\n",
        "                if data.shape[1]<random_features_number:\n",
        "                    network_results_test.update({random_features_number:float('nan')})\n",
        "                    continue\n",
        "                subsample_data = subsample_img_features(data, random_features_number, 100)\n",
        "                if exp_name == '2a':\n",
        "                    evalutaion_measure = analysis_fn(subsample_data, labels, performance_measure, exp_name)\n",
        "                    network_results_test.update({random_features_number:evalutaion_measure})\n",
        "                elif exp_name == '2b':\n",
        "                    for color in range(labels.shape[1]):\n",
        "                        evalutaion_measure = analysis_fn(subsample_data, labels[:,color], performance_measure, exp_name)\n",
        "                        network_results_test[random_features_number].update({color:evalutaion_measure})\n",
        "                elif exp_name == '2c':\n",
        "                    temp = []\n",
        "                    for letter in range(labels.shape[1]):\n",
        "                        evalutaion_measure = analysis_fn(subsample_data, labels[:,letter], performance_measure, exp_name)\n",
        "                        temp.append(evalutaion_measure)\n",
        "                        network_results_test[random_features_number].update({letter:evalutaion_measure})\n",
        "                else:\n",
        "                    logging.error('Only logistic regression implemented for experiment 2a and 2b')\n",
        "            results_test.update({layer:network_results_test})\n",
        "            dir_path = os.path.join(results_dir, exp_name)\n",
        "            if not os.path.exists(dir_path):\n",
        "                os.makedirs(dir_path)\n",
        "            with open(os.path.join(results_dir,exp_name, result_fname), 'wb') as f:\n",
        "                pickle.dump(results_test, f)\n",
        "            logging.info('Total time %d'%(time.time()-start_time))\n",
        "\n",
        "\n",
        "def logistic_regression(data, labels, performance_measure, exp_name):\n",
        "    if exp_name == '1c':\n",
        "        label_0_idx = np.where(labels==0)[0]\n",
        "        label_1_idx = np.where(labels==1)[0]\n",
        "        num_stimuli = 430\n",
        "        label_0_data = data[label_0_idx[:num_stimuli]]\n",
        "        label_1_data = data[label_1_idx[:num_stimuli]]\n",
        "        data = np.concatenate((label_0_data, label_1_data))\n",
        "        labels = np.concatenate((np.zeros(num_stimuli), np.ones(num_stimuli))).reshape(-1)\n",
        "        logging.info('data shape : %r, labels shape : %r, label_0 : %r, label:1,  %r'%(data.shape, labels.shape, label_0_idx.shape, label_1_idx.shape))\n",
        "    \n",
        "    elif exp_name == '2a':\n",
        "        # this is because we want to use all the data and labels for exp 2a\n",
        "        pass\n",
        "    elif exp_name in ['2b', '2c']:\n",
        "        label_0_idx = np.where(labels==0)[0]\n",
        "        label_1_idx = np.where(labels==1)[0]\n",
        "        if exp_name == '2b':\n",
        "            num_stimuli = 329\n",
        "        elif exp_name == '2c':\n",
        "           num_stimuli = 773\n",
        "        label_0_data = data[label_0_idx[:num_stimuli]]\n",
        "        label_1_data = data[label_1_idx[:num_stimuli]]\n",
        "        data = np.concatenate((label_0_data, label_1_data))\n",
        "        labels = np.concatenate((np.zeros(num_stimuli), np.ones(num_stimuli))).reshape(-1)\n",
        "        logging.info('data shape : %r, labels shape : %r, label_0 : %r, label:1,  %r'%(data.shape, labels.shape, label_0_idx.shape, label_1_idx.shape))\n",
        "    # x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=42)\n",
        "    # baseline_acc_test = max(np.count_nonzero(y_test==0)/y_test.shape[0], np.count_nonzero(y_test==1)/y_test.shape[0])\n",
        "    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "    model = LogisticRegression(random_state=1, max_iter=1000, solver='liblinear')\n",
        "    scores = cross_val_score(model, data, labels, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "    DEBUG = True\n",
        "    if DEBUG:\n",
        "        y_pred = cross_val_predict(model, data, labels, cv=10)\n",
        "        conf_mat = confusion_matrix(labels, y_pred)\n",
        "        logging.info('Confusion matrix : %r'%conf_mat)\n",
        "    # model.fit(x_train, y_train)\n",
        "    logging.info('test data label 0 :%r,  label 1:%r'%(np.where(data==0)[0].shape, np.where(labels==1)[0].shape))\n",
        "    if performance_measure == 'accuracy':\n",
        "        # return model.score(x_test, y_test)\n",
        "        return np.mean(scores)\n",
        "    else:\n",
        "        logging.error(\"Performance measure not implemented\")\n",
        "    # return num_stimuli\n",
        "\n",
        "def linear_regression(data, labels, performance_measure, exp_name):\n",
        "    # x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
        "    kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "    percentage_abs_error_list = []\n",
        "    rmspe_list = []\n",
        "    rmse_list = []\n",
        "    for train_index, test_index in kf.split(data):\n",
        "        x_train, x_test = data[train_index], data[test_index]\n",
        "        y_train, y_test = labels[train_index], labels[test_index]\n",
        "        model = LinearRegression() \n",
        "        model.fit(x_train,y_train)\n",
        "        y_pred = model.predict(x_test)\n",
        "        percentage_abs_error = np.average(np.abs(y_pred-y_test)/y_test) * 100\n",
        "        percentage_abs_error_list.append(percentage_abs_error) \n",
        "        rmspe = (np.sqrt(np.mean(np.square((y_test - y_pred) / y_test)))) * 100\n",
        "        rmspe_list.append(rmspe)\n",
        "        rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "        rmse_list.append(rmse)\n",
        "    # rmse_train = np.sqrt(metrics.mean_squared_error(y_train, model.predict(x_train)))\n",
        "    if performance_measure == 'percentage_abs_error':\n",
        "        return np.mean(percentage_abs_error_list)\n",
        "    elif performance_measure == 'rmspe':\n",
        "        return np.mean(rmspe_list)\n",
        "    elif performance_measure == 'rmse':\n",
        "        return np.mean(rmse_list)\n",
        "    else:\n",
        "        logging.error(\"Performance measure not implemented\")\n",
        "\n",
        "\n",
        "\n",
        "def get_data_and_labels(stim_type, layer, intermediate_layer_feats_dir, analysis_type, condition):\n",
        "    \"\"\"\n",
        "    Returns intermediate layer features and corresponding\n",
        "    labels. \n",
        "    Labels are one hot encoded for logistic regression and \n",
        "    float (average size otherwise)\n",
        "\n",
        "    condition is set size for avg.size experiments and color diversity otherwise\n",
        "    \"\"\"\n",
        "    part_1_fname = 'resnet_50_features_{}_{}_part_1.h5'.format(stim_type, layer)\n",
        "    part_2_fname = 'resnet_50_features_{}_{}_part_2.h5'.format(stim_type, layer)\n",
        "    try:\n",
        "        data_1 = np.concatenate(np.asarray(dd.io.load(os.path.join(intermediate_layer_feats_dir, part_1_fname))['features'],dtype = 'float16'))\n",
        "        if layer != 'avg_pool':\n",
        "            data_1 = np.squeeze(np.apply_over_axes(np.mean, data_1, [1, 2]))\n",
        "    except ValueError:\n",
        "        # occurs because part_1 file is empty because batch_size < dataset_size\n",
        "        logging.info('Value error while loading data 1')\n",
        "        logging.info(\"%r %r %r %r %r\", stim_type, layer, intermediate_layer_feats_dir, analysis_type, condition)\n",
        "    logging.info('dict 1 loaded')\n",
        "    data_2 = np.concatenate(np.asarray(dd.io.load(os.path.join(intermediate_layer_feats_dir, part_2_fname))['features']))\n",
        "    if layer != 'avg_pool':\n",
        "        data_2 = np.squeeze(np.apply_over_axes(np.mean, data_2, [1, 2]))\n",
        "    if stim_type in ['low_diversity', 'high_diversity']: # because of value error, data_1 is empty\n",
        "        data = data_2\n",
        "    else:\n",
        "        data = np.concatenate((data_1, data_2))\n",
        "    data.astype('float16')\n",
        "    logging.info('dict 2 loaded')\n",
        "    fnames = pickle.load(open(os.path.join(intermediate_layer_feats_dir , \"filenames_{}.p\".format(stim_type)), \"rb\" ))\n",
        "    labels = []\n",
        "    if analysis_type == 'logistic_regression':\n",
        "        if condition in [4, 8, 10, 16]:\n",
        "            for fname in fnames['fnames']:\n",
        "                temp = fname.split('_')[-1].split('.png')\n",
        "                radii = ast.literal_eval(temp[0])\n",
        "                # pre processing code for logistic regression dataset with no confounds\n",
        "                # temp = fname.split('radii')[-1].split('.png')[0]\n",
        "                # temp = temp[1:-1]\n",
        "                # temp = temp.split(' ')\n",
        "                # temp = [i[:-1] if '_' in i else i for i in temp]\n",
        "                # radii = [float(i) for i in temp if i != '']\n",
        "                assert(len(radii) == condition)\n",
        "                labels.append(radii)\n",
        "            one_hot = MultiLabelBinarizer()\n",
        "            one_hot_encoded = one_hot.fit_transform(labels)\n",
        "            assert(np.asarray(data).shape[0]==np.asarray(labels).shape[0])\n",
        "            return np.asarray(data), np.asarray(one_hot_encoded)\n",
        "        elif condition in ['low_diversity', 'high_diversity']:\n",
        "            for fname in fnames['fnames']:\n",
        "                if stim_type == 'low_diversity':\n",
        "                    labels.append(0)\n",
        "                elif stim_type == 'high_diversity':\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    logging.error('Only high and low diversity stimuli allowed')\n",
        "            return np.asarray(data), np.asarray(labels)\n",
        "        elif condition in ['ind_color']:\n",
        "            for fname in fnames['fnames']:\n",
        "                temp = fname.split('test_array_')[-1].split('_[')\n",
        "                colors_rgb = ast.literal_eval(temp[0])\n",
        "                labels.append(colors_rgb)\n",
        "            assert(np.asarray(data).shape[0]==np.asarray(labels).shape[0])\n",
        "            one_hot = MultiLabelBinarizer()\n",
        "            one_hot_encoded_colors = one_hot.fit_transform(labels)\n",
        "            return np.asarray(data), np.asarray(one_hot_encoded_colors)\n",
        "        elif condition in ['ind_letter']:\n",
        "            for fname in fnames['fnames']:\n",
        "                letters = [i for i in fname.split(']_[')[-1].split('.png')[0] if i.isupper()]\n",
        "                labels.append(letters)\n",
        "            assert(np.asarray(data).shape[0]==np.asarray(labels).shape[0])\n",
        "            one_hot = MultiLabelBinarizer()\n",
        "            one_hot_encoded_letters = one_hot.fit_transform(labels)\n",
        "            return np.asarray(data), np.asarray(one_hot_encoded_letters)\n",
        "        else:\n",
        "            logging.error('Only color diversity and average size experiments implemented')\n",
        "\n",
        "    elif analysis_type == 'linear_regression':\n",
        "        if condition in [4, 8, 10, 16]:\n",
        "            if stim_type in ['test_stim', 'ind']:\n",
        "                for fname in fnames['fnames']:\n",
        "                    temp = fname.split('_')[-1].split('.png')\n",
        "                    radii = ast.literal_eval(temp[0])\n",
        "                    # pre processing code for logistic regression dataset with no confounds\n",
        "                    # temp = fname.split('radii')[-1].split('.png')[0]\n",
        "                    # temp = temp[1:-1]\n",
        "                    # temp = temp.split(' ')\n",
        "                    # temp = [i[:-1] if '_' in i else i for i in temp]\n",
        "                    # radii = [float(i) for i in temp if i != '']\n",
        "                    if stim_type == 'ind':\n",
        "                        # Sanity check stimuli have single circles so there should be only 1 radius in the list\n",
        "                        # assert(type(radii[0])== float)\n",
        "                        assert(type(radii)== float)\n",
        "                        # assert(len(radii) == 1)\n",
        "                    else:\n",
        "                        assert(len(radii) == condition)\n",
        "                    labels.append(np.mean(radii))\n",
        "                assert(np.asarray(data).shape[0]==np.asarray(labels).shape[0])\n",
        "                return np.asarray(data), np.asarray(labels)\n",
        "            else:\n",
        "                logging.error(\"Only Ind and Test Stim implemented\")\n",
        "        else:\n",
        "            print('Only average size implemented for linear regression')\n",
        "    else:\n",
        "        logging.error(\"Invalid type of analysis. Only linear regression and logistic regression implemented\")\n",
        "\n",
        "    \n",
        "\n",
        "def subsample_img_features(data, n_features, seed):\n",
        "    \"\"\"\n",
        "    Subsamples data(img_features) \n",
        "    TO DO - implement tsne\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    indices = random.sample(range(0, data.shape[1]), n_features)\n",
        "    data_subset = []\n",
        "    for instance in data:\n",
        "        data_subset.append([instance[index] for index in indices])\n",
        "    return np.asarray(data_subset)\n",
        "        "
      ],
      "metadata": {
        "cellView": "form",
        "id": "y_MTDuBoT-uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title helper functions - Visualise results\n",
        "\n",
        "\n",
        "mpl.rcParams['figure.facecolor'] = 'white'\n",
        "\n",
        "# regression_dirs = [regression_results_set_size_4, regression_results_set_size_8, regression_results_set_size_10, regression_results_set_size_16]\n",
        "def plot_graphs(regression_dirs, fname, plot_title, x_label, y_label, \n",
        "                subsampling_levels, mode, figsize, ylim, legend_title, \n",
        "                analysis_type, exp_name, export_df_stats, exp_results_dir):\n",
        "    \"\"\"\n",
        "    Takes in the directories of the saved pickled files\n",
        "    of each set size and plots accuracy~layer_name*sampling_size\n",
        "    for multiple set sizes\n",
        "\n",
        "    fname - name of the pickle file which you want to plot\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, len(regression_dirs), figsize=figsize)\n",
        "    if export_df_stats:\n",
        "        average_fit_list = []\n",
        "        layer_list = []\n",
        "        units_list = []\n",
        "        set_size_list = []\n",
        "    for subplot, regression_dir in enumerate(regression_dirs):\n",
        "        infile = open(os.path.join(regression_dir, fname), 'rb')\n",
        "        var_fit_results = pickle.load(infile)\n",
        "        infile.close()\n",
        "        # column_names = [i.split('.')[0].split('_features')[0] for i in var_fit_results.keys()]\n",
        "        data = {}\n",
        "        if \"1\" in exp_name:\n",
        "            for key in var_fit_results.keys():\n",
        "                row_names = var_fit_results[key].keys()\n",
        "                if analysis_type == 'logistic_regression':\n",
        "                    accuracy = []\n",
        "                    for row in row_names:\n",
        "                        ind_accuracy = []\n",
        "                        if type(var_fit_results[key][row]) is dict:\n",
        "                            for circle_size in var_fit_results[key][row].keys():\n",
        "                                ind_accuracy += [var_fit_results[key][row][circle_size]]\n",
        "                                #accuracy += [sum(ind_accuracy)/len(ind_accuracy)]\n",
        "                            accuracy += [np.mean(ind_accuracy)]\n",
        "                        else:\n",
        "                            accuracy += [float('nan')]\n",
        "                    data.update({key.split('.')[0].split('_features')[0]:accuracy})\n",
        "                else:\n",
        "                    performance_measure = [(var_fit_results[key][i]) for i in row_names]\n",
        "                    data.update({key.split('.')[0].split('_features')[0]:performance_measure})\n",
        "        elif \"2\" in exp_name:\n",
        "            for key in var_fit_results.keys():\n",
        "                row_names = var_fit_results[key].keys()\n",
        "                if exp_name == '2a':\n",
        "                    performance_measure = [(var_fit_results[key][i]) for i in row_names]\n",
        "                    data.update({key.split('.')[0].split('_features')[0]:performance_measure}) \n",
        "                elif exp_name in ['2b', '2c']:\n",
        "                    accuracy = []\n",
        "                    for row in row_names:\n",
        "                        ind_accuracy = []\n",
        "                        if type(var_fit_results[key][row]) is dict:\n",
        "                            for color in var_fit_results[key][row].keys():\n",
        "                                ind_accuracy += [var_fit_results[key][row][color]]\n",
        "                                #accuracy += [sum(ind_accuracy)/len(ind_accuracy)]\n",
        "                            accuracy += [np.mean(ind_accuracy)]\n",
        "                        else:\n",
        "                            accuracy += [float('nan')]\n",
        "                    data.update({key.split('.')[0].split('_features')[0]:accuracy})\n",
        "                else:\n",
        "                    print('Only implemented plotting for 2a, 2b, 2c in exp 2')   \n",
        "        else:\n",
        "            print('Only exp 1 and exp 2 implemented')\n",
        "        num_of_subsampling_levels = list(set([len(data[key]) for key in data.keys()]))[0]\n",
        "        assert(num_of_subsampling_levels in [10,20,50,100,200,500])\n",
        "        df = pd.DataFrame(data)\n",
        "        layer_names = df.columns\n",
        "        df = df.T\n",
        "        df.columns = row_names\n",
        "        average_fit = []\n",
        "        for i in reversed(df.values):\n",
        "            average_fit += list(i)\n",
        "        layer = []\n",
        "        for layer_name in reversed(layer_names):\n",
        "            if layer_name == 'avg_pool':\n",
        "                layer += ['pre_final']*num_of_subsampling_levels\n",
        "            elif layer_name == 'pool1_pool':\n",
        "                layer += ['conv1(pool1_pool)']*num_of_subsampling_levels\n",
        "            else:\n",
        "                layer += [layer_name]*num_of_subsampling_levels\n",
        "        if num_of_subsampling_levels == 10:\n",
        "            units = [10,20,50,100,200,500, 800, 1000, 1500, 2000]*layer_names.shape[0]\n",
        "        elif num_of_subsampling_levels == 6:\n",
        "            units = [10,20,50,100,200,500]*layer_names.shape[0]\n",
        "        else:\n",
        "            print('Invalid number of subsampling levels')\n",
        "        \n",
        "        reg_df = pd.DataFrame({\"performace_measure\":average_fit, \"layer\":layer, \"units\":units})\n",
        "        if export_df_stats:\n",
        "            average_fit_list += average_fit\n",
        "            layer_list += layer\n",
        "            units_list += units\n",
        "            set_size_list += [regression_dir.split('_')[-1][:-1]]*len(average_fit)\n",
        "            continue\n",
        "    \n",
        "        reg_df = reg_df[reg_df.units.isin(subsampling_levels)]\n",
        "        \n",
        "        if len(regression_dirs) == 1:\n",
        "            subplot = ax\n",
        "        else:\n",
        "            subplot = ax[subplot]\n",
        "        if len(subsampling_levels) == 1:\n",
        "            subplot.plot(reg_df['layer'],reg_df['performace_measure'])\n",
        "        else: \n",
        "            # TO DO :- Add functionality to support plotting of any gives subsampling levels\n",
        "            # RIght now, only one or all is supported\n",
        "            fig = interaction_plot(np.asarray(layer), units, average_fit, ax = subplot, \n",
        "                                xlabel = \"     \", ylabel = \"      \")\n",
        "            # fig = interaction_plot(list(reg_df['layer']), list(reg_df['units']), \n",
        "            #                     np.array(reg_df['accuracy']), ax = subplot)  \n",
        "        if mode == 'avg_size':\n",
        "            subplot.set_title('Set Size {}'.format(regression_dir.split('_')[-1][:-1]), fontsize = 25)\n",
        "        elif mode == 'color_diversity':\n",
        "            pass\n",
        "        else:\n",
        "            print('Unspecified mode')\n",
        "        subplot.set_ylabel('', fontsize = 25)\n",
        "        subplot.set_ylim(ylim)\n",
        "        subplot.tick_params(axis='y', which='major', labelsize=25)\n",
        "        subplot.tick_params(axis='x', which='major', labelsize=15)\n",
        "\n",
        "        subplot.legend().set_visible(False)\n",
        "    if export_df_stats:\n",
        "        export_data_df = pd.DataFrame({\"performace_measure\":average_fit_list, \"layer\":layer_list, \"units\":units_list, \"set_size\":set_size_list}) \n",
        "        export_data_df.to_csv(os.path.join(exp_results_dir, 'long_format_exp_data.csv'), index=False)\n",
        "        return\n",
        "    if mode == 'avg_size':\n",
        "        if len(subsampling_levels) != 1:\n",
        "            lines_labels = ax[0].get_legend_handles_labels()\n",
        "            lines, labels = lines_labels[0], lines_labels[1]\n",
        "            fig.legend(lines, labels, title = legend_title)\n",
        "    else:\n",
        "        if len(subsampling_levels) != 1:\n",
        "            lines_labels = subplot.get_legend_handles_labels()\n",
        "            lines, labels = lines_labels[0], lines_labels[1]\n",
        "            fig.legend(lines, labels, title = legend_title)\n",
        "          \n",
        "    # fig.legend(handles, labels, loc='upper center')\n",
        "    fig.supylabel(y_label, fontsize = 25)\n",
        "    fig.supxlabel(x_label, fontsize = 25)\n",
        "    fig.suptitle(plot_title, fontsize=30)\n",
        "    plt.close()\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_graphs_single(regression_dirs, fname, plot_title, x_label, y_label, \n",
        "                subsampling_levels, mode, figsize, ylim, legend_title, \n",
        "            analysis_type, exp_name):\n",
        "    \"\"\"\n",
        "    Takes in the directories of the saved pickled files\n",
        "    of each set size and plots accuracy~layer_name*sampling_size\n",
        "    for multiple set sizes\n",
        "\n",
        "    fname - name of the pickle file which you want to plot\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "    for regression_dir in regression_dirs:\n",
        "        infile = open(os.path.join(regression_dir, fname), 'rb')\n",
        "        var_fit_results = pickle.load(infile)\n",
        "        infile.close()\n",
        "        # column_names = [i.split('.')[0].split('_features')[0] for i in var_fit_results.keys()]\n",
        "        data = {}\n",
        "        if \"1\" in exp_name:\n",
        "            for key in var_fit_results.keys():\n",
        "                row_names = var_fit_results[key].keys()\n",
        "                if analysis_type == 'logistic_regression':\n",
        "                    accuracy = []\n",
        "                    for row in row_names:\n",
        "                        ind_accuracy = []\n",
        "                        if type(var_fit_results[key][row]) is dict:\n",
        "                            for circle_size in var_fit_results[key][row].keys():\n",
        "                                ind_accuracy += [var_fit_results[key][row][circle_size]]\n",
        "                                #accuracy += [sum(ind_accuracy)/len(ind_accuracy)]\n",
        "                            accuracy += [np.mean(ind_accuracy)]\n",
        "                        else:\n",
        "                            accuracy += [float('nan')]\n",
        "                    data.update({key.split('.')[0].split('_features')[0]:accuracy})\n",
        "                else:\n",
        "                    performance_measure = [(var_fit_results[key][i]) for i in row_names]\n",
        "                    data.update({key.split('.')[0].split('_features')[0]:performance_measure})\n",
        "        elif \"2\" in exp_name:\n",
        "            for key in var_fit_results.keys():\n",
        "                row_names = var_fit_results[key].keys()\n",
        "                if exp_name == '2a':\n",
        "                    performance_measure = [(var_fit_results[key][i]) for i in row_names]\n",
        "                    data.update({key.split('.')[0].split('_features')[0]:performance_measure}) \n",
        "                elif exp_name in ['2b', '2c']:\n",
        "                    accuracy = []\n",
        "                    for row in row_names:\n",
        "                        ind_accuracy = []\n",
        "                        if type(var_fit_results[key][row]) is dict:\n",
        "                            for color in var_fit_results[key][row].keys():\n",
        "                                ind_accuracy += [var_fit_results[key][row][color]]\n",
        "                                #accuracy += [sum(ind_accuracy)/len(ind_accuracy)]\n",
        "                            accuracy += [np.mean(ind_accuracy)]\n",
        "                        else:\n",
        "                            accuracy += [float('nan')]\n",
        "                    data.update({key.split('.')[0].split('_features')[0]:accuracy})\n",
        "                else:\n",
        "                    print('Only implemented plotting for 2a, 2b, 2c in exp 2')   \n",
        "        else:\n",
        "            print('Only exp 1 and exp 2 implemented')\n",
        "        num_of_subsampling_levels = list(set([len(data[key]) for key in data.keys()]))[0]\n",
        "        assert(num_of_subsampling_levels in [10,20,50,100,200,500])\n",
        "        df = pd.DataFrame(data)\n",
        "        layer_names = df.columns\n",
        "        df = df.T\n",
        "        df.columns = row_names\n",
        "        average_fit = []\n",
        "        for i in reversed(df.values):\n",
        "            average_fit += list(i)\n",
        "        layer = []\n",
        "        for layer_name in reversed(layer_names):\n",
        "            if layer_name == 'avg_pool':\n",
        "                layer += ['pre_final']*num_of_subsampling_levels\n",
        "            elif layer_name == 'pool1_pool':\n",
        "                layer += ['conv1(pool1_pool)']*num_of_subsampling_levels\n",
        "            else:\n",
        "                layer += [layer_name]*num_of_subsampling_levels\n",
        "        if num_of_subsampling_levels == 10:\n",
        "            units = [10,20,50,100,200,500, 800, 1000, 1500, 2000]*layer_names.shape[0]\n",
        "        elif num_of_subsampling_levels == 6:\n",
        "            units = [10,20,50,100,200,500]*layer_names.shape[0]\n",
        "        else:\n",
        "            print('Invalid number of subsampling levels')\n",
        "        \n",
        "        reg_df = pd.DataFrame({\"performace_measure\":average_fit, \"layer\":layer, \"units\":units})\n",
        "        reg_df = reg_df[reg_df.units.isin(subsampling_levels)]\n",
        "        \n",
        "        subplot = ax\n",
        "\n",
        "        if len(subsampling_levels) == 1:\n",
        "            subplot.plot(reg_df['layer'],reg_df['performace_measure'])\n",
        "        else: \n",
        "            # TO DO :- Add functionality to support plotting of any gives subsampling levels\n",
        "            # RIght now, only one or all is supported\n",
        "            fig = interaction_plot(np.asarray(layer), units, average_fit, ax = subplot, \n",
        "                                xlabel = \"     \", ylabel = \"      \")\n",
        "            # fig = interaction_plot(list(reg_df['layer']), list(reg_df['units']), \n",
        "            #                     np.array(reg_df['accuracy']), ax = subplot)  \n",
        "        subplot.set_ylabel('', fontsize = 25)\n",
        "        subplot.set_ylim(ylim)\n",
        "        subplot.tick_params(axis='y', which='major', labelsize=25)\n",
        "        subplot.tick_params(axis='x', which='major', labelsize=15)\n",
        "    if mode == 'avg_size':\n",
        "        if len(subsampling_levels) != 1:\n",
        "            lines_labels = ax[0].get_legend_handles_labels()\n",
        "            lines, labels = lines_labels[0], lines_labels[1]\n",
        "            fig.legend(lines, labels, title = legend_title)\n",
        "    else:\n",
        "        if len(subsampling_levels) != 1:\n",
        "            lines_labels = subplot.get_legend_handles_labels()\n",
        "            lines, labels = lines_labels[0], lines_labels[1]\n",
        "            fig.legend(lines, labels, title = legend_title)\n",
        "          \n",
        "    # fig.legend(handles, labels, loc='upper center')\n",
        "    if exp_name not in ['2a', '2b', '2c']:\n",
        "        subplot.legend([regression_dir.split('_')[-1][:-1] for regression_dir in regression_dirs], fontsize = 25)\n",
        "    fig.supylabel(y_label, fontsize = 25)\n",
        "    fig.supxlabel(x_label, fontsize = 25)\n",
        "    fig.suptitle(plot_title, fontsize=30)\n",
        "    plt.close()\n",
        "    return fig\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UIJWPuC-hT7r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncezp9kmIEqb"
      },
      "source": [
        "# Average Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtRbaxMWSbF4"
      },
      "outputs": [],
      "source": [
        "Size\n",
        "# Download data\n",
        "# Generate activation of avg_pool and pool1\n",
        "# Perform experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Efi-ghuIEqb"
      },
      "source": [
        "## Extract intermediate layer representations - should take about 10 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GMvdZxAxIEqc",
        "outputId": "dc6ff77a-755c-47a1-c01e-8db2f1f5f192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b504866be029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mintermediate_layer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINTERMEDIATE_LAYER_NAMES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data/average_size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstim_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ind'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'INTERMEDIATE_LAYER_NAMES' is not defined"
          ]
        }
      ],
      "source": [
        "model_name = 'resnet50'\n",
        "intermediate_layer_names = INTERMEDIATE_LAYER_NAMES\n",
        "dataset_dir = os.path.join(BASE_DIR, \"data/average_size\")\n",
        "batch_size = BATCH_SIZE\n",
        "stim_type = 'ind'\n",
        "features_dir = os.path.join(dataset_dir, \"features\")\n",
        "conditions = [4, 8]\n",
        "exp_name = '1a'\n",
        "extract_intermediate_layer_representations(model_name=model_name,\n",
        "                                            intermediate_layer_names = intermediate_layer_names,\n",
        "                                            dataset_base_dir = dataset_dir, \n",
        "                                            batch_size = batch_size, \n",
        "                                            stim_type = stim_type, \n",
        "                                            features_base_dir = features_dir, \n",
        "                                            conditions = conditions, \n",
        "                                            exp_name = exp_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z69DouFGIEqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6c39d6-ec2f-4f54-bff2-00b714808b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "model_name = 'resnet50'\n",
        "intermediate_layer_names = INTERMEDIATE_LAYER_NAMES\n",
        "dataset_dir = os.path.join(BASE_DIR, \"data/average_size\")\n",
        "batch_size = BATCH_SIZE\n",
        "stim_type = 'test_stim'\n",
        "features_dir = os.path.join(dataset_dir, \"features\")\n",
        "conditions = [4, 8]\n",
        "exp_name = '1b'\n",
        "extract_intermediate_layer_representations(model_name=model_name,\n",
        "                                            intermediate_layer_names = intermediate_layer_names,\n",
        "                                            dataset_base_dir = dataset_dir, \n",
        "                                            batch_size = batch_size, \n",
        "                                            stim_type = stim_type, \n",
        "                                            features_base_dir = features_dir, \n",
        "                                            conditions = conditions, \n",
        "                                            exp_name = exp_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "QxCBQ9nhR0fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Are individual circle sizes represented by CNNs trained on naturalistic images?"
      ],
      "metadata": {
        "id": "LaBY0hrzR58D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp_name = '1a'\n",
        "features_dir = os.path.join(dataset_dir, \"features\")\n",
        "subsampling_levels = [10, 20, 50]\n",
        "conditions = [4, 8]\n",
        "intermediate_layer_names = INTERMEDIATE_LAYER_NAMES\n",
        "results_dir = RESULTS_DIR\n",
        "performance_measure = 'rmspe'\n",
        "result_fname = 'sanity_check_rmspe'\n",
        "\n",
        "run_exp(exp_name = exp_name, \n",
        "            features_dir = features_dir, \n",
        "            subsampling_levels = subsampling_levels, \n",
        "            conditions = conditions, \n",
        "            intermediate_layer_names = intermediate_layer_names, \n",
        "            results_dir = RESULTS_DIR, \n",
        "            result_fname = result_fname, \n",
        "            performance_measure= performance_measure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJLTAvM1R3-8",
        "outputId": "f7f0e6b1-047f-4c10-b001-77a3ce10812e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:240: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:240: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:240: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:240: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0AaXqdS2UUo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Is the ensemble representation of average size represented by CNNs trained on naturalistic images?"
      ],
      "metadata": {
        "id": "FwwSqvKPWei6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp_name = '1b'\n",
        "features_dir = os.path.join(dataset_dir, \"features\")\n",
        "subsampling_levels = [10, 20, 50]\n",
        "conditions = [4, 8]\n",
        "intermediate_layer_names = INTERMEDIATE_LAYER_NAMES\n",
        "results_dir = RESULTS_DIR\n",
        "performance_measure = 'rmspe'\n",
        "result_fname = 'sanity_check_rmspe'\n",
        "\n",
        "run_exp(exp_name = exp_name, \n",
        "            features_dir = features_dir, \n",
        "            subsampling_levels = subsampling_levels, \n",
        "            conditions = conditions, \n",
        "            intermediate_layer_names = intermediate_layer_names, \n",
        "            results_dir = RESULTS_DIR, \n",
        "            result_fname = result_fname, \n",
        "            performance_measure= performance_measure)"
      ],
      "metadata": {
        "outputId": "6398f6b6-c687-4581-db9e-0a4217bd8b85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxAsiCj9Wei7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:240: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:240: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:240: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:240: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What happens to the individual representations in the ensemble?"
      ],
      "metadata": {
        "id": "BzUhF8i_78QA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp_name = '1c'\n",
        "features_dir = os.path.join(dataset_dir, \"features\")\n",
        "subsampling_levels = [10, 20, 50]\n",
        "conditions = [4, 8]\n",
        "intermediate_layer_names = INTERMEDIATE_LAYER_NAMES\n",
        "results_dir = RESULTS_DIR\n",
        "performance_measure = 'rmspe'\n",
        "result_fname = 'sanity_check_rmspe'\n",
        "\n",
        "run_exp(exp_name = exp_name, \n",
        "            features_dir = features_dir, \n",
        "            subsampling_levels = subsampling_levels, \n",
        "            conditions = conditions, \n",
        "            intermediate_layer_names = intermediate_layer_names, \n",
        "            results_dir = RESULTS_DIR, \n",
        "            result_fname = result_fname, \n",
        "            performance_measure= performance_measure)"
      ],
      "metadata": {
        "id": "3Ne5rzXr8FxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualise results"
      ],
      "metadata": {
        "id": "P4BrBT06hFLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Are individual circle sizes represented by CNNs trained on naturalistic images?"
      ],
      "metadata": {
        "id": "VcMq5rjPjXH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp_1a_results_dir = os.path.join(RESULTS_DIR, '1a')\n",
        "exp_1a_results_set_size_4 = os.path.join(exp_1a_results_dir, 'set_size_4/')\n",
        "exp_1a_results_set_size_8 = os.path.join(exp_1a_results_dir, 'set_size_8/')\n",
        "\n",
        "exp_1a_dirs_to_plot = [exp_1a_results_set_size_4, exp_1a_results_set_size_8]\n",
        "fig = plot_graphs(regression_dirs = exp_1a_dirs_to_plot, fname = 'sanity_check_1a_rmspe.pkl', \n",
        "                                    plot_title = 'Individual circle size error', x_label = 'Layer Names', y_label = 'RMSPE', subsampling_levels=[10,20,50], \n",
        "                                    mode = 'avg_size', figsize = (54, 15), ylim = (0, 30), legend_title = 'Subsamples', analysis_type = 'lienar_regression', exp_name = '1a')\n",
        "fig"
      ],
      "metadata": {
        "id": "ww9xzNPxhIWH",
        "outputId": "73b71237-c230-4d63-aefb-323c48d2cbf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-22fbc08956e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp_1a_results_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexp_1a_results_set_size_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_1a_results_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set_size_4/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexp_1a_results_set_size_8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_1a_results_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set_size_8/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexp_1a_dirs_to_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexp_1a_results_set_size_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_1a_results_set_size_8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RESULTS_DIR' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Is the ensemble representation of average size represented by CNNs trained on naturalistic images?"
      ],
      "metadata": {
        "id": "ygYwej2qkHEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp_1b_results_dir = os.path.join(RESULTS_DIR, '1b')\n",
        "exp_1b_results_set_size_4 = os.path.join(exp_1b_results_dir, 'set_size_4/')\n",
        "exp_1b_results_set_size_8 = os.path.join(exp_1b_results_dir, 'set_size_8/')\n",
        "exp_1b_dirs_to_plot = [exp_1b_results_set_size_4, exp_1b_results_set_size_8]\n",
        "fig = plot_graphs(regression_dirs = exp_1b_dirs_to_plot, fname = 'avg_size_1b.pkl', \n",
        "                                    plot_title = 'Average size error', x_label = 'Layer Names', y_label = 'RMSPE', subsampling_levels=[10,20,50], \n",
        "                                    mode = 'avg_size', figsize = (54, 15), ylim = (0, 20), legend_title = 'Subsamples',  analysis_type = 'logistic_regression', exp_name = '2a', \n",
        "                                    export_df_stats = False, exp_results_dir = None)\n",
        "fig"
      ],
      "metadata": {
        "id": "9_pC4KxOkPBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What happens to the individual representations in the ensemble?"
      ],
      "metadata": {
        "id": "E1li_mAClOLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp_1c_results_dir = os.path.join(RESULTS_DIR, '1c')\n",
        "exp_1c_results_set_size_4 = os.path.join(exp_1c_results_dir, 'set_size_4/')\n",
        "exp_1c_results_set_size_8 = os.path.join(exp_1c_results_dir, 'set_size_8/')\n",
        "exp_1c_dirs_to_plot = [exp_1c_results_set_size_4, exp_1c_results_set_size_8]\n",
        "fig = plot_graphs(regression_dirs = exp_1c_dirs_to_plot, fname = 'logistic_regression_1c.pkl', \n",
        "                                    plot_title = 'Logistic Regression Individual Circle', x_label = 'Layer Names', y_label = 'Accuracy', subsampling_levels=[50], \n",
        "                                    mode = 'avg_size', figsize = (54, 15), ylim = (0.5, 0.8), legend_title = 'Subsamples', analysis_type = 'logistic_regression', exp_name = '1c')\n",
        "fig\n"
      ],
      "metadata": {
        "id": "-5Ht-ejglPjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('ensemble_representations')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "d51e2fff98dacac56a168894eab35c66d31737be860e3214143049a454647912"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}