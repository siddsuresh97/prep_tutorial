{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddsuresh97/prep_tutorial/blob/main/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download files - run this only once\n",
        "\n",
        "import zipfile\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/siddsuresh97/prep_tutorial/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/tmp/prep_cnn_psychophysics.zip\"\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/tmp/prep_cnn_psychophysics.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_eY8yM9wIKa6",
        "outputId": "4115ee03-4df2-4176-f41f-42491f9f6e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-06 15:33:03--  https://github.com/siddsuresh97/prep_tutorial/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/siddsuresh97/prep_tutorial/zip/refs/heads/main [following]\n",
            "--2022-07-06 15:33:03--  https://codeload.github.com/siddsuresh97/prep_tutorial/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/tmp/prep_cnn_psychophysics.zip’\n",
            "\n",
            "/tmp/prep_cnn_psych     [       <=>          ] 100.93M  19.5MB/s    in 5.3s    \n",
            "\n",
            "2022-07-06 15:33:08 (19.1 MB/s) - ‘/tmp/prep_cnn_psychophysics.zip’ saved [105834558]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qNnGKH1LXwYi",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title imports\n",
        "\n",
        "!pip install deepdish -q\n",
        "\n",
        "import logging\n",
        "import zipfile\n",
        "import gc\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import deepdish as dd\n",
        "\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_resnet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtRbaxMWSbF4"
      },
      "outputs": [],
      "source": [
        "Size\n",
        "# Download data\n",
        "# Generate activation of avg_pool and pool1\n",
        "# Perform experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JFOIVV0XIEqZ"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = '/tmp/prep_tutorial-main'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "sJfxRVikIEqZ"
      },
      "outputs": [],
      "source": [
        "#@title helper functions - intermediate layer features\n",
        "\n",
        "\n",
        "def store_dataset_fnames(intermediate_layer_names, dataset_dir, batch_size, stim_type, features_dir):\n",
        "    # Stores filenames of stimuli in a pickle file\n",
        "    # Fnames of stimuli contain metadata about labels\n",
        "    # Only one intermediate layer is used because the fnames are same regardless of the intermediate layer\n",
        "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input_resnet50)\n",
        "    if not os.path.exists(features_dir):\n",
        "        os.makedirs(features_dir)\n",
        "    for layer in intermediate_layer_names[0]:\n",
        "        generator = datagen.flow_from_directory(dataset_dir, shuffle = False, batch_size = batch_size)\n",
        "        filenames = generator.filenames\n",
        "        fname_dict = {'fnames':filenames}\n",
        "        pickle.dump( fname_dict, open(os.path.join(features_dir,\"filenames_{}.p\".format(stim_type)), \"wb\" ))  \n",
        "    logging.info(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n",
        "\n",
        "def store_intermediate_layer_features(model_name, intermediate_layer_names, dataset_dir, batch_size, stim_type, features_dir):\n",
        "    for layer in intermediate_layer_names:\n",
        "        logging.info('------------------------------- {} ----------------------------'.format(layer))\n",
        "        if model_name == 'resnet50':\n",
        "            datagen = ImageDataGenerator(preprocessing_function=preprocess_input_resnet50)\n",
        "        else:\n",
        "            logging.error('Models apart from resnet50 not implemented')\n",
        "        generator = datagen.flow_from_directory(dataset_dir, shuffle = False, batch_size = batch_size, target_size = (224, 224))\n",
        "        len = generator.n\n",
        "        batches = np.ceil(len/batch_size)\n",
        "        extract_and_store(model_name, 1, layer, generator, features_dir, stim_type, batches)\n",
        "        extract_and_store(model_name, 2, layer, generator, features_dir, stim_type, batches)\n",
        "    return\n",
        "\n",
        "\n",
        "def extract_intermediate_layer_representations(model_name, intermediate_layer_names, dataset_base_dir, batch_size, stim_type, features_base_dir, conditions, exp_name):\n",
        "    \"\"\"\n",
        "    This function extracts and stores intermediate layer representations given a model\n",
        "    and a dataset   \n",
        "    \"\"\"\n",
        "    if exp_name == '1a':\n",
        "        stim_name = 'random_stim'\n",
        "    elif exp_name == '1b':\n",
        "        stim_name = 'test_stim' \n",
        "    else:\n",
        "        logging.error('Only Exp 1a, 1b implemented')\n",
        "\n",
        "    # condition is set size if exp is 1a or 1b, otherwise it is color diveristy\n",
        "    for condition in conditions:\n",
        "        if exp_name in ['1a' or '1b']:\n",
        "            dataset_dir = os.path.join(dataset_base_dir, '{}_generated_stimuli'.format(condition), stim_name)\n",
        "            features_dir = os.path.join(features_base_dir, 'set_size_{}'.format(condition))\n",
        "        elif exp_name in ['2a']:\n",
        "            stim_type = condition\n",
        "            dataset_dir = os.path.join(dataset_base_dir, condition)\n",
        "            features_dir = os.path.join(features_base_dir)\n",
        "        else:\n",
        "            logging.error('Only 1a, 1b, 2a activation extraction implemented')\n",
        "        store_dataset_fnames(intermediate_layer_names, dataset_dir, batch_size, stim_type, features_dir)\n",
        "        start = time.time()\n",
        "        store_intermediate_layer_features(model_name, intermediate_layer_names, dataset_dir, batch_size, stim_type, features_dir)\n",
        "        logging.info('Total time to extract intermediate layer reprsentations (in seconds): {}'.format(time.time()-start))\n",
        "\n",
        "\n",
        "def extract_and_store(model_name, part, layer, generator, features_dir, stim_type, batches):\n",
        "    '''\n",
        "    Extracts intermediate layer features and stores them in two h5 files\n",
        "    '''\n",
        "    if model_name == 'resnet50':\n",
        "        model = ResNet50(weights='imagenet', include_top=True)\n",
        "    else:\n",
        "        logging.error('Models apart from resnet not implementde')\n",
        "    extractor = tf.keras.Model(inputs=model.inputs,\n",
        "                                outputs=[model.get_layer(layer).output])\n",
        "    features_dict = {'fnames':[],'features':[]}\n",
        "    if part == 1:\n",
        "        min_range = 0\n",
        "        max_range = int(batches)//2\n",
        "    elif part == 2:\n",
        "        min_range = int(batches)//2\n",
        "        max_range = int(batches)\n",
        "    for batch in range(min_range, max_range):\n",
        "        time_for_generator_operation = time.time()\n",
        "        x,y = generator.next()\n",
        "        # logging.info('Time for generator %f' % time.time()-time_for_generator_operation)\n",
        "        time_for_prediction = time.time()\n",
        "        generator_features = extractor.predict(x)\n",
        "        features_dict['features'].append(generator_features)\n",
        "        # logging.info('Prediction Time = %f'%time.time()-time_for_prediction)\n",
        "        time_for_deletion = time.time()\n",
        "        del generator_features\n",
        "        # logging.info('Time_for_deletion = ', time.time()-time_for_deletion)\n",
        "        idx = (generator.batch_index - 1) * generator.batch_size\n",
        "        features_dict['fnames'].append(generator.filenames[idx : idx + generator.batch_size])\n",
        "    del extractor\n",
        "    del model\n",
        "    if not os.path.exists(features_dir):\n",
        "        os.makedirs(features_dir)\n",
        "    dd.io.save(os.path.join(features_dir, 'resnet_50_features_{}_{}_part_{}.h5'.format(stim_type, layer, part)), features_dict)\n",
        "    del features_dict\n",
        "    gc.collect()\n",
        "    clear_session()\n",
        "    logging.info(\"Saved {} part {}\".format(layer, part))\n",
        "    return \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncezp9kmIEqb"
      },
      "source": [
        "# Average Size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Efi-ghuIEqb"
      },
      "source": [
        "## Extract intermediate layer representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GMvdZxAxIEqc",
        "outputId": "f46c1b48-3920-4964-f243-b509c9227835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n",
            "102981632/102967424 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ea568e042314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                                             \u001b[0mfeatures_base_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                             \u001b[0mconditions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconditions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                             exp_name = exp_name)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-fdd2d20aa711>\u001b[0m in \u001b[0;36mextract_intermediate_layer_representations\u001b[0;34m(model_name, intermediate_layer_names, dataset_base_dir, batch_size, stim_type, features_base_dir, conditions, exp_name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mstore_dataset_fnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstim_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mstore_intermediate_layer_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstim_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total time to extract intermediate layer reprsentations (in seconds): {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fdd2d20aa711>\u001b[0m in \u001b[0;36mstore_intermediate_layer_features\u001b[0;34m(model_name, intermediate_layer_names, dataset_dir, batch_size, stim_type, features_dir)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mextract_and_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstim_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mextract_and_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstim_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fdd2d20aa711>\u001b[0m in \u001b[0;36mextract_and_store\u001b[0;34m(model_name, part, layer, generator, features_dir, stim_type, batches)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet_50_features_{}_{}_part_{}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mfeatures_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved {} part {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
          ]
        }
      ],
      "source": [
        "model_name = 'resnet50'\n",
        "intermediate_layer_names = ['avg_pool', 'pool1_pool']\n",
        "dataset_dir = os.path.join(BASE_DIR, \"data/average_size\")\n",
        "batch_size = 512\n",
        "stim_type = 'avg_size'\n",
        "features_dir = os.path.join(dataset_dir, \"features\")\n",
        "conditions = [4, 8]\n",
        "exp_name = '1a'\n",
        "extract_intermediate_layer_representations(model_name=model_name,\n",
        "                                            intermediate_layer_names = intermediate_layer_names,\n",
        "                                            dataset_base_dir = dataset_dir, \n",
        "                                            batch_size = batch_size, \n",
        "                                            stim_type = stim_type, \n",
        "                                            features_base_dir = features_dir, \n",
        "                                            conditions = conditions, \n",
        "                                            exp_name = exp_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z69DouFGIEqc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('ensemble_representations')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "d51e2fff98dacac56a168894eab35c66d31737be860e3214143049a454647912"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}